{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e513fc-a12a-4bce-92fb-eff3c31b1fea",
   "metadata": {},
   "source": [
    "### Imports etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6236731-28dd-4ea2-a585-321a7a42b247",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#startup template for Jupyter Notebook\n",
    "# activate tab completion so I won't shy away from descriptive vars\n",
    "%config IPCompleter.use_jedi = False\n",
    "%config IPCompleter.greedy = True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6510bb9-91ed-476a-8da0-d262b76a1112",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from flipside import Flipside\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import requests\n",
    "import collections\n",
    "import warnings\n",
    "#from datetime import date, time, datetime, timedelta\n",
    "import time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import display, HTML, Markdown, Video, Javascript, Image\n",
    "# Allow for multiple outputs from one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"  # 'last' for last output other options: (last_expr, last_expr_or_assign, 'None')   \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c507709-4aa2-434d-b9d7-536e373c9bf6",
   "metadata": {},
   "source": [
    "#### query_flipside  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4633d665-3784-4206-9d6c-9c5cc75693b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./py/query_flipside.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile   './py/query_flipside.py'\n",
    "# You need to have a .env file with 'FLIPSIDE_API_KEY' defined.\n",
    "# parameters of the param objects for create_query_run may be passed. (e.g. `maxAgeMinutes = 500`)\n",
    "def query_flipside(sql, url='https://api-v2.flipsidecrypto.xyz/json-rpc', **kwargs):\n",
    "    load_dotenv()\n",
    "    headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'x-api-key': os.environ.get('FLIPSIDE_API_KEY')\n",
    "}\n",
    "    def create_query_run():\n",
    "        \n",
    "        params = [\n",
    "    {\n",
    "        \"resultTTLHours\": 1,\n",
    "        \"maxAgeMinutes\": 0,\n",
    "        \"sql\": sql,\n",
    "        \"dataSource\": \"snowflake-default\",\n",
    "        \"dataProvider\": \"flipside\"\n",
    "    }\n",
    "    ]\n",
    "        if kwargs != {}:\n",
    "            for key, value in kwargs:\n",
    "                params[0][key] = value\n",
    "    \n",
    "        payload = json.dumps({\n",
    "                \"jsonrpc\": \"2.0\",\n",
    "                \"method\": \"createQueryRun\",\n",
    "                \"params\": params,\n",
    "                \"id\": 42,\n",
    "                \"dataSource\": \"snowflake-default\",\n",
    "                \"dataProvider\": \"flipside\"\n",
    "                })\n",
    "        \n",
    "        #print('inside inner function')\n",
    "        try:\n",
    "            response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "            if response.status_code != 200 :\n",
    "                print (f\"API call received status: {response.status_code}. Exiting\")\n",
    "                return False\n",
    "                # print(f\"Status code: {response.status_code}\")\n",
    "            # print(f\"Response text: {response.text}\")\n",
    "        except: \n",
    "            print(\"error with API request in create_query_run\")\n",
    "            return False\n",
    "        #print(response.text)\n",
    "        try: \n",
    "            if response.json()['result']['queryRun']['state'] == \"QUERY_STATE_READY\":\n",
    "                query_run_id = response.json()['result']['queryRun']['id']\n",
    "                print(json.dumps(response.json()['result']['queryRequest'], indent=4))\n",
    "                return query_run_id\n",
    "            else:\n",
    "                print(\"Query state is not ready\")\n",
    "                return False\n",
    "        except MemoryError: \n",
    "            #print(f\"error with api request: {response.json()['error']['message']}\")\n",
    "            #print(\"response object has no result key\")\n",
    "            #print(response.text)\n",
    "            return False\n",
    "\n",
    "    \n",
    "    ################################################################################\n",
    "    #\n",
    "    # Get Query Run \n",
    "    #\n",
    "    ################################################################################\n",
    "    \n",
    "    def get_query_run():\n",
    "        load_dotenv()\n",
    "        payload = json.dumps({\n",
    "          \"jsonrpc\": \"2.0\",\n",
    "          \"method\": \"getQueryRun\",\n",
    "          \"params\": [\n",
    "            {\n",
    "              \"queryRunId\": query_run_id\n",
    "            }\n",
    "          ],\n",
    "          \"id\": 1\n",
    "        })\n",
    "        done = False\n",
    "        count = 0\n",
    "        time_start = time.time()\n",
    "        # %%writefile -a  './py/query_flipside.py'\n",
    "        while not done:\n",
    "            response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "            state = response.json()['result']['queryRun']['state']\n",
    "            if state == \"QUERY_STATE_SUCCESS\":\n",
    "                print(\"Success.\")\n",
    "                return True \n",
    "            if state != \"QUERY_STATE_RUNNING\":\n",
    "                print(f\"State {state} occured\")\n",
    "                return False\n",
    "            if count % 10 = 0:\n",
    "                print(f\"status is 'running' count = {count}\")\n",
    "            count += 1\n",
    "            time.sleep(3)\n",
    "            run_time = time.time() - time_start\n",
    "            if run_time  > 1000:\n",
    "                print(\"Taking to long. Exiting.\")\n",
    "                return False\n",
    "                \n",
    "            \n",
    "            \n",
    "            #print(json.dumps(response.json(), indent=4))\n",
    "     ################################################################################\n",
    "    #\n",
    "    # Get Query Run Results\n",
    "    #\n",
    "    ################################################################################\n",
    "    \n",
    "    def get_query_run_results():\n",
    "        payload = json.dumps({\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"method\": \"getQueryRunResults\",\n",
    "  \"params\": [\n",
    "    {\n",
    "      \"queryRunId\": query_run_id,\n",
    "      \"format\": \"json\",\n",
    "      \"page\": {\n",
    "        \"number\": 1,\n",
    "        \"size\": 100\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"id\": 1\n",
    "    })\n",
    "        response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "        return response.json()\n",
    "        \n",
    "    ################################################################################\n",
    "    #\n",
    "    # Main Body of query_flipside\n",
    "    #\n",
    "    ################################################################################\n",
    "    \n",
    "    query_run_id = create_query_run()\n",
    "    if not query_run_id:\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"Ready to send query_id '{query_run_id}' to `get_query_run`\")\n",
    "        if get_query_run():\n",
    "            print(\"Query success. Ready to get results!\")\n",
    "            results = get_query_run_results()\n",
    "            df = pd.DataFrame(results['result']['rows'])\n",
    "            return df\n",
    "        \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8821c28c-d88d-408e-a3ff-c342786aaaba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"clxnc9kd90g1zna0tjyjkmww8\",\n",
      "    \"sqlStatementId\": \"clxmkdlmq3ja6ou0t4pyicz9w\",\n",
      "    \"userId\": \"clgztx7jw00qxob0sc634x5rg\",\n",
      "    \"tags\": {},\n",
      "    \"maxAgeMinutes\": 0,\n",
      "    \"resultTTLHours\": 1,\n",
      "    \"userSkipCache\": true,\n",
      "    \"triggeredQueryRun\": true,\n",
      "    \"queryRunId\": \"clxnc9kcm0g1xna0th8kno7r2\",\n",
      "    \"createdAt\": \"2024-06-20T14:09:47.000Z\",\n",
      "    \"updatedAt\": \"2024-06-20T14:09:47.000Z\"\n",
      "}\n",
      "Ready to send query_id 'clxnc9kcm0g1xna0th8kno7r2' to `get_query_run`\n",
      "status is 'running' count = 0\n",
      "status is 'running' count = 1\n",
      "status is 'running' count = 2\n",
      "status is 'running' count = 3\n",
      "status is 'running' count = 4\n",
      "status is 'running' count = 5\n",
      "status is 'running' count = 6\n",
      "status is 'running' count = 7\n",
      "status is 'running' count = 8\n",
      "status is 'running' count = 9\n",
      "status is 'running' count = 10\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 11\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 12\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 13\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 14\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 15\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 16\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 17\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 18\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 19\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 20\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 21\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 22\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 23\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 24\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 25\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 26\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 27\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 28\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 29\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 30\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 31\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 32\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 33\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 34\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 35\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 36\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 37\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 38\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 39\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 40\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 41\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 42\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 43\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 44\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 45\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 46\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 47\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 48\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 49\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 50\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 51\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 52\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 53\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 54\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 55\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 56\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 57\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 58\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 59\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 60\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 61\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 62\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 63\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 64\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 65\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 66\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 67\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 68\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 69\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 70\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 71\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 72\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 73\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 74\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 75\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 76\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 77\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 78\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 79\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 80\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 81\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 82\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 83\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 84\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 85\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 86\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 87\n",
      "Taking to long. Exiting.\n",
      "Success.\n",
      "Query success. Ready to get results!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst_chain_id</th>\n",
       "      <th>dst_chain</th>\n",
       "      <th>__row_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>bnb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42161</td>\n",
       "      <td>arbitrum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>gnosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>fantom</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>122</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000</td>\n",
       "      <td>mantle</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>288</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>optimism</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dst_chain_id dst_chain  __row_index\n",
       "0            56       bnb            0\n",
       "1         42161  arbitrum            1\n",
       "2           100    gnosis            2\n",
       "3            66   Unknown            3\n",
       "4           250    fantom            4\n",
       "5            25   Unknown            5\n",
       "6           122   Unknown            6\n",
       "7          5000    mantle            7\n",
       "8           288   Unknown            8\n",
       "9            10  optimism            9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test script for making sure api is working\n",
    "# sql = \"\"\"\n",
    "# SELECT \n",
    "#   date_trunc('hour', block_timestamp) as hour,\n",
    "#   count(distinct tx_hash) as tx_count\n",
    "# FROM ethereum.core.fact_transactions \n",
    "# WHERE block_timestamp >= GETDATE() - interval'7 days'\n",
    "# GROUP BY 1\n",
    "# \"\"\"\n",
    "#query_flipside(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f07a99-ff46-4ac0-bf2e-0309e48c2f65",
   "metadata": {},
   "source": [
    "### Chain Ids table\n",
    "\n",
    "The below SQL script maps the chain ids used by Li.Fi to the human readable chain label. The choice of the polygon event logs table was arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22584b9d-2af1-4a4e-9cc5-e578f2a76282",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DST_CHAIN</th>\n",
       "      <th>CHAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42161</td>\n",
       "      <td>arbitrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>bnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>gnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>fantom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>zksync</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59144</td>\n",
       "      <td>linea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000</td>\n",
       "      <td>mantle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1088</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>81457</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1151111081099710</td>\n",
       "      <td>solana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1101</td>\n",
       "      <td>pol zkevm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8453</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43114</td>\n",
       "      <td>avalanche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>ethereum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34443</td>\n",
       "      <td>mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>534352</td>\n",
       "      <td>scroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>﻿</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DST_CHAIN      CHAIN\n",
       "0              42161   arbitrum\n",
       "1                 56        bnb\n",
       "2                100     gnosis\n",
       "3                250     fantom\n",
       "4                324     zksync\n",
       "5                 10   optimism\n",
       "6              59144      linea\n",
       "7               5000     mantle\n",
       "8               1088    Unknown\n",
       "9              81457    Unknown\n",
       "10  1151111081099710     solana\n",
       "11              1101  pol zkevm\n",
       "12              8453       base\n",
       "13             43114  avalanche\n",
       "14                 1   ethereum\n",
       "15             34443       mode\n",
       "16                30    Unknown\n",
       "17            534352     scroll\n",
       "18                 ﻿        NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chainIDs_df = pd.read_csv('data/chainIDs.csv')\n",
    "chainIDs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e79ff-fb03-4bad-bcf6-535f51997871",
   "metadata": {},
   "source": [
    "We won't be using that because we are just going to incorporate it into our SQL query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e0840a-6ee9-4b48-bb27-8eef8dfd279e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Building the raw table. \n",
    "\n",
    "Using a simple loop through the list of blockchains that we are interested in and `fstrings`, we can generate the script we need by unioning all the otherwise identical queries. Each blockchain has its own schema, with the same table structures. We will be able to easily reconstruct the query, by just editing our model instead of every CTE in the script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567beed-fe93-45e6-bf30-983b5dbe7f6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Components\n",
    "\n",
    " - Chain ID helper table (as seen above) First CTE of our query\n",
    " - For each chain we query three tables\n",
    "    - the `<chain name>.core.ez_decoded_event_logs` table \n",
    "    - the `<chain name>core.ez_native_transfers` table for native token transfers\n",
    "    - the `<chain name>core.ez_transfers` table for erc20 transfers\n",
    " - We first query the `log_events` table and join it with the `chainIDs` table, for each blocckchain, assigning the value '<blockchain>' to a `chain` column (e.g. select 'bsc' as chain)\n",
    " - We then union all the tables.\n",
    " - Next we iterate through the chains again, this time joining together the results from the native and erc20 transfer tables. We label the source_token as 'native' when querying the `native_token_transfers` table.\n",
    " - Finally, we join together the bridge data with the transfer data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41f54d-53c4-4ad0-951b-3b728d6e95cb",
   "metadata": {},
   "source": [
    "### The SQL\n",
    "\n",
    "The first part of the querry string, `sql` is the query for the `chainIDs` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "153ab857-0860-443e-b1a3-71612235f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_string(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        sql = f.read()\n",
    "    return sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5e7bfeb-4798-4a3b-b3e6-51d2bc2a46c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with chain_ids as (\n",
      "select distinct decoded_log:bridgeData:destinationChainId as dst_chain_ID,\n",
      "                case\n",
      "                  when dst_chain_ID = 1 then 'ethereum'\n",
      "                  when dst_chain_ID = 8453 then 'base'\n",
      "                  when dst_chain_ID = 137 then 'polygon'\n",
      "                  when dst_chain_ID = 42161 then 'arbitrum'\n",
      "                  when dst_chain_ID = 10 then 'optimism'\n",
      "                  when dst_chain_ID = 56 then 'bnb'\n",
      "                  when dst_chain_ID = 43114 then 'avalanche'\n",
      "                  when dst_chain_ID = 1101 then 'pol zkevm'\n",
      "                  when dst_chain_ID = 59144 then 'linea'\n",
      "                  when dst_chain_ID = 100 then 'gnosis'\n",
      "                  when dst_chain_ID = 250 then 'fantom'\n",
      "                  when dst_chain_ID = 5000 then 'mantle'\n",
      "                  when dst_chain_ID = 1313161554 then 'aurora'\n",
      "                  when dst_chain_ID = 7777777 then 'zora'\n",
      "                  when dst_chain_ID = 324 then 'zksync'\n",
      "                  when dst_chain_ID = 1151111081099710 then 'solana'\n",
      "                  when dst_chain_ID = 534352 then 'scroll'\n",
      "                  when dst_chain_ID = 34443 then 'mode'\n",
      "                  else 'Unknown'\n",
      "                end as dst_chain\n",
      "\n",
      "from polygon.core.ez_decoded_event_logs \n",
      "where  event_name = 'LiFiTransferStarted'\n",
      ")\n",
      "select * from chain_ids\n",
      "\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "sql = get_sql_string('Scripts/sql/chainIDs.sql')\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82d9706e-c8b2-422e-8770-01daccce58b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"clxndvzrp0vkyoo0twhaefif6\",\n",
      "    \"sqlStatementId\": \"clxmkdlmq3ja6ou0t4pyicz9w\",\n",
      "    \"userId\": \"clgztx7jw00qxob0sc634x5rg\",\n",
      "    \"tags\": {},\n",
      "    \"maxAgeMinutes\": 0,\n",
      "    \"resultTTLHours\": 1,\n",
      "    \"userSkipCache\": true,\n",
      "    \"triggeredQueryRun\": true,\n",
      "    \"queryRunId\": \"clxndvzqw0vkwoo0t5vbl2tie\",\n",
      "    \"createdAt\": \"2024-06-20T14:55:13.000Z\",\n",
      "    \"updatedAt\": \"2024-06-20T14:55:13.000Z\"\n",
      "}\n",
      "Ready to send query_id 'clxndvzqw0vkwoo0t5vbl2tie' to `get_query_run`\n",
      "status is 'running' count = 0\n",
      "status is 'running' count = 1\n",
      "status is 'running' count = 2\n",
      "status is 'running' count = 3\n",
      "status is 'running' count = 4\n",
      "status is 'running' count = 5\n",
      "status is 'running' count = 6\n",
      "status is 'running' count = 7\n",
      "status is 'running' count = 8\n",
      "status is 'running' count = 9\n",
      "status is 'running' count = 10\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 11\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 12\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 13\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 14\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 15\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 16\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 17\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 18\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 19\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 20\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 21\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 22\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 23\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 24\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 25\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 26\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 27\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 28\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 29\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 30\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 31\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 32\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 33\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 34\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 35\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 36\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 37\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 38\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 39\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 40\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 41\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 42\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 43\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 44\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 45\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 46\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 47\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 48\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 49\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 50\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 51\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 52\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 53\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 54\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 55\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 56\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 57\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 58\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 59\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 60\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 61\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 62\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 63\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 64\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 65\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 66\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 67\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 68\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 69\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 70\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 71\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 72\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 73\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 74\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 75\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 76\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 77\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 78\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 79\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 80\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 81\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 82\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 83\n",
      "Taking to long. Exiting.\n",
      "status is 'running' count = 84\n",
      "Taking to long. Exiting.\n",
      "State QUERY_STATE_STREAMING_RESULTS occured\n"
     ]
    }
   ],
   "source": [
    "query_flipside(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dacd992-a7f7-4014-bf17-520187d2e24a",
   "metadata": {},
   "source": [
    "### query_run_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95de07fb-d343-4c4d-9e43-bb9dee3cc268",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"columnNames\":[\"dst_chain_id\",\"dst_chain\",\"__row_index\"],\"columnTypes\":[\"number\",\"string\",\"number\"],\"rows\":[[250,\"fantom\",0]],\"page\":{\"currentPageNumber\":1,\"currentPageSize\":1,\"totalRows\":28,\"totalPages\":28},\"sql\":\"select * from read_parquet('/data/2024/06/20/14/clxndvzqw0vkwoo0t5vbl2tie/*') offset 0 limit 1\",\"format\":\"csv\",\"originalQueryRun\":{\"id\":\"clxndvzqw0vkwoo0t5vbl2tie\",\"sqlStatementId\":\"clxmkdlmq3ja6ou0t4pyicz9w\",\"state\":\"QUERY_STATE_SUCCESS\",\"path\":\"2024/06/20/14/clxndvzqw0vkwoo0t5vbl2tie\",\"fileCount\":1,\"lastFileNumber\":null,\"fileNames\":\"clxndvzqw0vkwoo0t5vbl2tie_results.parquet\",\"errorName\":null,\"errorMessage\":null,\"errorData\":null,\"dataSourceQueryId\":\"01b5233f-0504-fde1-3d4f-830227680bcb\",\"dataSourceSessionId\":\"17257400591461618\",\"startedAt\":\"2024-06-20T14:55:13.000Z\",\"queryRunningEndedAt\":\"2024-06-20T14:59:53.000Z\",\"queryStreamingEndedAt\":\"2024-06-20T14:59:53.000Z\",\"endedAt\":\"2024-06-20T14:59:53.000Z\",\"rowCount\":28,\"totalSize\":\"1151\",\"tags\":{},\"dataSourceId\":\"clf90gwee0002jvbu63diaa8u\",\"userId\":\"clgztx7jw00qxob0sc634x5rg\",\"createdAt\":\"2024-06-20T14:55:13.000Z\",\"updatedAt\":\"2024-06-20T14:55:13.000Z\",\"archivedAt\":null,\"rowsPerResultSet\":20000000,\"statementTimeoutSeconds\":900,\"abortDetachedQuery\":true},\"redirectedToQueryRun\":null}}\n"
     ]
    }
   ],
   "source": [
    "def query_run_results(queryRunId):\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "url = \"https://api-v2.flipsidecrypto.xyz/json-rpc\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"method\": \"getQueryRunResults\",\n",
    "  \"params\": [\n",
    "    {\n",
    "      \"queryRunId\": queryRunId,\n",
    "      \"format\": \"csv\",\n",
    "      \"page\": {\n",
    "        \"number\": 1000,\n",
    "        \"size\": 10000\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"id\": 1\n",
    "})\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'x-api-key': '025c9fa7-616d-40d2-8756-701e6cf43f82'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3ba37-729d-4d8d-9e40-aacce7193829",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sql = \"\"\"\n",
    "# -- forked from all_chains_bridge_data @ https://flipsidecrypto.xyz/edit/queries/41f7b717-670a-4d7b-add9-0b5d2e214b18\n",
    "\n",
    "# -- forked from octavionotpunk / Jumper Source Chain\n",
    "# --  @ https://flipsidecrypto.xyz/octavionotpunk/q/JIUX5KquZLfu/jumper-source-chainselect \n",
    "\n",
    "# with chain_ids as (\n",
    "#           select distinct decoded_log:bridgeData:destinationChainId as dst_chain_ID,\n",
    "#                 case\n",
    "#                   when dst_chain_ID = 1 then 'ethereum'\n",
    "#                   when dst_chain_ID = 8453 then 'base'\n",
    "#                   when dst_chain_ID = 137 then 'polygon'\n",
    "#                   when dst_chain_ID = 42161 then 'arbitrum'\n",
    "#                   when dst_chain_ID = 10 then 'optimism'\n",
    "#                   when dst_chain_ID = 56 then 'bnb'\n",
    "#                   when dst_chain_ID = 43114 then 'avalanche'\n",
    "#                   # when dst_chain_ID = 1101 then 'pol zkevm'\n",
    "#                   when dst_chain_ID = 59144 then 'linea'\n",
    "#                   when dst_chain_ID = 100 then 'gnosis'\n",
    "#                   when dst_chain_ID = 250 then 'fantom'\n",
    "#                   when dst_chain_ID = 5000 then 'mantle'\n",
    "#                   when dst_chain_ID = 1313161554 then 'aurora'\n",
    "#                   when dst_chain_ID = 7777777 then 'zora'\n",
    "#                   when dst_chain_ID = 324 then 'zksync'\n",
    "#                   when dst_chain_ID = 1151111081099710 then 'solana'\n",
    "#                   when dst_chain_ID = 534352 then 'scroll'\n",
    "#                   when dst_chain_ID = 34443 then 'mode'\n",
    "#                   else 'Unknown'\n",
    "#                 end as dst_chain\n",
    "# from polygon.core.ez_decoded_event_logs \n",
    "# where  event_name = 'LiFiTransferStarted'\n",
    "#   and block_timestamp > current_timestamp - interval '1 day'\n",
    "# ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54434238-7811-452c-832e-6806ab185388",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sql = \"\"\"\n",
    "# -- forked from all_chains_bridge_data @ https://flipsidecrypto.xyz/edit/queries/41f7b717-670a-4d7b-add9-0b5d2e214b18\n",
    "\n",
    "# -- forked from octavionotpunk / Jumper Source Chain\n",
    "# --  @ https://flipsidecrypto.xyz/octavionotpunk/q/JIUX5KquZLfu/jumper-source-chainselect \n",
    "\n",
    "# with chain_ids as (\n",
    "#           select distinct decoded_log:bridgeData:destinationChainId as dst_chain_ID,\n",
    "#                 case\n",
    "#                   when dst_chain_ID = 1 then 'ethereum'\n",
    "#                   when dst_chain_ID = 8453 then 'base'\n",
    "#                   when dst_chain_ID = 137 then 'polygon'\n",
    "#                   when dst_chain_ID = 42161 then 'arbitrum'\n",
    "#                   when dst_chain_ID = 10 then 'optimism'\n",
    "#                   when dst_chain_ID = 56 then 'bnb'\n",
    "#                   when dst_chain_ID = 43114 then 'avalanche'\n",
    "#                   # when dst_chain_ID = 1101 then 'pol zkevm'\n",
    "#                   when dst_chain_ID = 59144 then 'linea'\n",
    "#                   when dst_chain_ID = 100 then 'gnosis'\n",
    "#                   when dst_chain_ID = 250 then 'fantom'\n",
    "#                   when dst_chain_ID = 5000 then 'mantle'\n",
    "#                   when dst_chain_ID = 1313161554 then 'aurora'\n",
    "#                   when dst_chain_ID = 7777777 then 'zora'\n",
    "#                   when dst_chain_ID = 324 then 'zksync'\n",
    "#                   when dst_chain_ID = 1151111081099710 then 'solana'\n",
    "#                   when dst_chain_ID = 534352 then 'scroll'\n",
    "#                   when dst_chain_ID = 34443 then 'mode'\n",
    "#                   else 'Unknown'\n",
    "#                 end as dst_chain\n",
    "# from polygon.core.ez_decoded_event_logs \n",
    "# where  event_name = 'LiFiTransferStarted'\n",
    "#   and block_timestamp > current_timestamp - interval '1 day'\n",
    "# ),\n",
    "\n",
    "  \n",
    "# polygon_raw_bridge_data as (\n",
    "#               select decoded_log:bridgeData:destinationChainId as dst_chain_id,\n",
    "#                      decoded_log:bridgeData:bridge as bridge,\n",
    "#                      decoded_log:bridgeData:integrator as integrator,\n",
    "#                      event_name,\n",
    "#                      tx_hash\n",
    "#               from polygon.core.ez_decoded_event_logs\n",
    "#               where event_name =  'LiFiTransferStarted'\n",
    "#                 and block_timestamp > current_timestamp - interval '30 days'\n",
    "# ),\n",
    "# polygon_bridge_data as (\n",
    "#   select 'polygon' as source_chain,\n",
    "#          c.dst_chain,\n",
    "#           r.bridge,\n",
    "#          r.integrator,\n",
    "#            r.event_name,\n",
    "#          r.tx_hash\n",
    "#   from chain_ids c\n",
    "#         left join \n",
    "#         polygon_raw_bridge_data r \n",
    "#         using\n",
    "#         (dst_chain_id)\n",
    "# ),\n",
    "# bsc_raw_bridge_data as (\n",
    "#           select decoded_log:bridgeData:destinationChainId as dst_chain_id,\n",
    "#                  decoded_log:bridgeData:bridge as bridge,\n",
    "#                  decoded_log:bridgeData:integrator as integrator,\n",
    "#                  event_name,\n",
    "#                  tx_hash\n",
    "#           from bsc.core.ez_decoded_event_logs\n",
    "#           where event_name =  'LiFiTransferStarted'\n",
    "#             and block_timestamp > (current_timestamp - interval '30 days')\n",
    "# ),\n",
    "# bsc_bridge_data as (\n",
    "#   select 'bsc' as source_chain,\n",
    "#          c.dst_chain,\n",
    "#          r.bridge,\n",
    "#          r.integrator,\n",
    "#          r.event_name,\n",
    "#          r.tx_hash\n",
    "#   from chain_ids c\n",
    "#         left join \n",
    "#         bsc_raw_bridge_data r \n",
    "#         using\n",
    "#         (dst_chain_id)\n",
    "# ),\n",
    "# arbitrum_raw_bridge_data as (\n",
    "#           select decoded_log:bridgeData:destinationChainId as dst_chain_id,\n",
    "#                  decoded_log:bridgeData:bridge as bridge,\n",
    "#                  decoded_log:bridgeData:integrator as integrator,\n",
    "#                  event_name,\n",
    "#                  tx_hash\n",
    "#           from arbitrum.core.ez_decoded_event_logs\n",
    "#           where event_name =  'LiFiTransferStarted'\n",
    "#             and block_timestamp > current_timestamp - interval '30 days'\n",
    "# ),\n",
    "# arbitrum_bridge_data as (\n",
    "#   select 'arbitrum' as source_chain,\n",
    "#          c.dst_chain,\n",
    "#          r.bridge,\n",
    "#          r.integrator,\n",
    "#          r.event_name,\n",
    "#          r.tx_hash\n",
    "#   from chain_ids c\n",
    "#         left join \n",
    "#         arbitrum_raw_bridge_data r \n",
    "#         using\n",
    "#         (dst_chain_id)\n",
    "# ),\n",
    "# optimism_raw_bridge_data as (\n",
    "#           select decoded_log:bridgeData:destinationChainId as dst_chain_id,\n",
    "#                  decoded_log:bridgeData:bridge as bridge,\n",
    "#                  decoded_log:bridgeData:integrator as integrator,\n",
    "#                  event_name,\n",
    "#                  tx_hash\n",
    "#           from optimism.core.ez_decoded_event_logs\n",
    "#           where event_name =  'LiFiTransferStarted'\n",
    "#             and block_timestamp > current_timestamp - interval '30 days'\n",
    "# ),\n",
    "# optimism_bridge_data as (\n",
    "#   select 'optimism' as source_chain,\n",
    "#          c.dst_chain,\n",
    "#          r.bridge,\n",
    "#          r.integrator,\n",
    "#          r.event_name,\n",
    "#          r.tx_hash\n",
    "#   from chain_ids c\n",
    "#         left join \n",
    "#         optimism_raw_bridge_data r \n",
    "#         using\n",
    "#         (dst_chain_id)\n",
    "# ),\n",
    "# base_raw_bridge_data as (\n",
    "#           select decoded_log:bridgeData:destinationChainId as dst_chain_id,\n",
    "#                  decoded_log:bridgeData:bridge as bridge,\n",
    "#                  decoded_log:bridgeData:integrator as integrator,\n",
    "#                  event_name,\n",
    "#                  tx_hash\n",
    "#           from base.core.ez_decoded_event_logs\n",
    "#           where event_name =  'LiFiTransferStarted'\n",
    "#             and block_timestamp > current_timestamp - interval '30 days'\n",
    "# ),\n",
    "# base_bridge_data as (\n",
    "#   select 'base' as source_chain,\n",
    "#          c.dst_chain,\n",
    "#          r.bridge,\n",
    "#          r.integrator,\n",
    "#          r.event_name,\n",
    "#          r.tx_hash\n",
    "#   from chain_ids c\n",
    "#         left join \n",
    "#         base_raw_bridge_data r \n",
    "#         using\n",
    "#         (dst_chain_id)\n",
    "# ),\n",
    "# avalanche_raw_bridge_data as (\n",
    "#           select decoded_log:bridgeData:destinationChainId as dst_chain_id,\n",
    "#                  decoded_log:bridgeData:bridge as bridge,\n",
    "#                  decoded_log:bridgeData:integrator as integrator,\n",
    "#                  event_name,\n",
    "#                  tx_hash\n",
    "#           from avalanche.core.ez_decoded_event_logs\n",
    "#           where event_name =  'LiFiTransferStarted'\n",
    "#             and block_timestamp > current_timestamp - interval '30 days'\n",
    "# ),\n",
    "# avalanche_bridge_data as (\n",
    "#   select 'avalanche' as source_chain,\n",
    "#          c.dst_chain,\n",
    "#          r.bridge,\n",
    "#          r.integrator,\n",
    "#          r.event_name,\n",
    "#          r.tx_hash\n",
    "#   from chain_ids c\n",
    "#         left join \n",
    "#         avalanche_raw_bridge_data r \n",
    "#         using\n",
    "#         (dst_chain_id)\n",
    "# ),\n",
    "# ethereum_raw_bridge_data as (\n",
    "#           select decoded_log:bridgeData:destinationChainId as dst_chain_id,\n",
    "#                  decoded_log:bridgeData:bridge as bridge,\n",
    "#                  decoded_log:bridgeData:integrator as integrator,\n",
    "#                  event_name,\n",
    "#                  tx_hash\n",
    "#           from ethereum.core.ez_decoded_event_logs\n",
    "#           where event_name =  'LiFiTransferStarted'\n",
    "#             and block_timestamp > current_timestamp - interval '30 days'\n",
    "# ),\n",
    "# ethereum_bridge_data as (\n",
    "#   select 'ethereum' as source_chain,\n",
    "#          c.dst_chain,\n",
    "#          r.bridge,\n",
    "#          r.integrator,\n",
    "#          r.event_name,\n",
    "#          r.tx_hash\n",
    "#   from chain_ids c\n",
    "#         left join \n",
    "#         ethereum_raw_bridge_data r \n",
    "#         using\n",
    "#         (dst_chain_id)\n",
    "# ),\n",
    "\n",
    "\n",
    "# all_chains_bridge_data as (\n",
    "# select * from polygon_bridge_data\n",
    "#  union all \n",
    "# select * from bsc_bridge_data\n",
    "#  union all\n",
    "# select * from arbitrum_bridge_data\n",
    "#  union all\n",
    "# select * from optimism_bridge_data\n",
    "#  union all\n",
    "# select * from base_bridge_data\n",
    "#  union all\n",
    "# select * from avalanche_bridge_data\n",
    "#  union all\n",
    "# select * from ethereum_bridge_data\n",
    "# ),\n",
    "# -- forked from all_chians_transfers_data @ https://flipsidecrypto.xyz/edit/queries/4d7fcf48-7560-447d-84b4-89eed256fdfe\n",
    "\n",
    "#     arbitrum_transfers as (\n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  'native' as source_token, \n",
    "#     \t  tx_hash \n",
    "#      from arbitrum.core.ez_native_transfers\n",
    "#      where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#        and block_timestamp > current_timestamp - interval '30 days'\n",
    "#        and amount_usd >= 20\n",
    "    \n",
    "#     union all\n",
    "    \n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  symbol as source_token, \n",
    "#     \t  tx_hash \n",
    "#     from  arbitrum.core.ez_token_transfers\n",
    "#     where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#       and block_timestamp > current_timestamp - interval '30 days'\n",
    "#       and amount_usd >= 20\n",
    "#     ),\n",
    "    \n",
    "\n",
    "#     avalanche_transfers as (\n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  'native' as source_token, \n",
    "#     \t  tx_hash \n",
    "#      from avalanche.core.ez_native_transfers\n",
    "#      where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#        and block_timestamp > current_timestamp - interval '30 days'\n",
    "#        and amount_usd >= 20\n",
    "    \n",
    "#     union all\n",
    "    \n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  symbol as source_token, \n",
    "#     \t  tx_hash \n",
    "#     from  avalanche.core.ez_token_transfers\n",
    "#     where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#       and block_timestamp > current_timestamp - interval '30 days'\n",
    "#       and amount_usd >= 20\n",
    "#     ),\n",
    "    \n",
    "\n",
    "#     base_transfers as (\n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  'native' as source_token, \n",
    "#     \t  tx_hash \n",
    "#      from base.core.ez_native_transfers\n",
    "#      where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#        and block_timestamp > current_timestamp - interval '30 days'\n",
    "#        and amount_usd >= 20\n",
    "    \n",
    "#     union all\n",
    "    \n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  symbol as source_token, \n",
    "#     \t  tx_hash \n",
    "#     from  base.core.ez_token_transfers\n",
    "#     where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#       and block_timestamp > current_timestamp - interval '30 days'\n",
    "#       and amount_usd >= 20\n",
    "#     ),\n",
    "    \n",
    "\n",
    "#     bsc_transfers as (\n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  'native' as source_token, \n",
    "#     \t  tx_hash \n",
    "#      from bsc.core.ez_native_transfers\n",
    "#      where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#        and block_timestamp > current_timestamp - interval '30 days'\n",
    "#        and amount_usd >= 20\n",
    "    \n",
    "#     union all\n",
    "    \n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  symbol as source_token, \n",
    "#     \t  tx_hash \n",
    "#     from  bsc.core.ez_token_transfers\n",
    "#     where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#       and block_timestamp > current_timestamp - interval '30 days'\n",
    "#       and amount_usd >= 20\n",
    "#     ),\n",
    "    \n",
    "\n",
    "#     ethereum_transfers as (\n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  'native' as source_token, \n",
    "#     \t  tx_hash \n",
    "#      from ethereum.core.ez_native_transfers\n",
    "#      where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#        and block_timestamp > current_timestamp - interval '30 days'\n",
    "#        and amount_usd >= 20\n",
    "    \n",
    "#     union all\n",
    "    \n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  symbol as source_token, \n",
    "#     \t  tx_hash \n",
    "#     from  ethereum.core.ez_token_transfers\n",
    "#     where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#       and block_timestamp > current_timestamp - interval '30 days'\n",
    "#       and amount_usd >= 20\n",
    "#     ),\n",
    "    \n",
    "\n",
    "#     optimism_transfers as (\n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  'native' as source_token, \n",
    "#     \t  tx_hash \n",
    "#      from optimism.core.ez_native_transfers\n",
    "#      where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#        and block_timestamp > current_timestamp - interval '30 days'\n",
    "#        and amount_usd >= 20\n",
    "    \n",
    "#     union all\n",
    "    \n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  symbol as source_token, \n",
    "#     \t  tx_hash \n",
    "#     from  optimism.core.ez_token_transfers\n",
    "#     where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#       and block_timestamp > current_timestamp - interval '30 days'\n",
    "#       and amount_usd >= 20\n",
    "#     ),\n",
    "    \n",
    "\n",
    "#     polygon_transfers as (\n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  'native' as source_token, \n",
    "#     \t  tx_hash \n",
    "#      from polygon.core.ez_native_transfers\n",
    "#      where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#        and block_timestamp > current_timestamp - interval '30 days'\n",
    "#        and amount_usd >= 20\n",
    "    \n",
    "#     union all\n",
    "    \n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  symbol as source_token, \n",
    "#     \t  tx_hash \n",
    "#     from  polygon.core.ez_token_transfers\n",
    "#     where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#       and block_timestamp > current_timestamp - interval '30 days'\n",
    "#       and amount_usd >= 20\n",
    "#     ),\n",
    "#     all_chains_transfer_data as (\n",
    "#       select * from polygon_transfers\n",
    "#        union all \n",
    "#       select * from bsc_transfers\n",
    "#        union all\n",
    "#       select * from arbitrum_transfers\n",
    "#        union all\n",
    "#       select * from optimism_transfers\n",
    "#        union all\n",
    "#       select * from base_transfers\n",
    "#        union all\n",
    "#       select * from avalanche_transfers\n",
    "#        union all\n",
    "#       select * from ethereum_transfers\n",
    "#    ),\n",
    "# --select * from  all_chains_bridge_data  limit 10\n",
    "# --select * from  all_chains_transfer_data  limit 10\n",
    "# final as  (\n",
    "# select t.block_timestamp, \n",
    "#        t.from_address,\n",
    "#        round(t.amount_usd,2) as amount_usd, \n",
    "#        t.source_token,\n",
    "#        b.dst_chain,\n",
    "#        b.bridge,\n",
    "#        b.integrator,\n",
    "#       -- b.event_name\n",
    "       \n",
    "# from all_chains_transfer_data  t\n",
    "#       join \n",
    "#      all_chains_bridge_data b\n",
    "#      using(tx_hash)\n",
    "#  )\n",
    "# select * from final limit 5\n",
    "#  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b28642-fc3a-4599-8901-0ec8fb9c1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT \n",
    "  date_trunc('hour', block_timestamp) as hour,\n",
    "  count(distinct tx_hash) as tx_count\n",
    "FROM ethereum.core.fact_transactions \n",
    "WHERE block_timestamp >= GETDATE() - interval'7 days'\n",
    "GROUP BY 1\n",
    "\"\"\"\n",
    "response_create = create_query(sql)\n",
    "id = response_create['result']['queryRun']['id']\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e7fbc-8bb2-492c-b378-f2b4e04c6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 'clxcuoy0944teod0tk8tdxjt4'\n",
    "query_run = run_query(id)\n",
    "query_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c66d6c-72bf-4b08-996d-3fc6909f79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chains = ['arbitrum', 'bsc', 'optimism', 'base', 'avalanche', 'ethereum','polygon']\n",
    "# chains.sort()\n",
    "# sql = \"\"\n",
    "# for chain in chains:\n",
    "#     query[chain] = \n",
    "\n",
    "# sql = f\"\"\"\n",
    "# {chain}_raw_bridge_data as (\n",
    "#           select decoded_log:bridgeData:destinationChainId as dst_chain_id,\n",
    "#                  decoded_log:bridgeData:bridge as bridge,\n",
    "#                  decoded_log:bridgeData:integrator as integrator,\n",
    "#                  tx_hash\n",
    "#           from {chain}.core.ez_decoded_event_logs\n",
    "#           where event_name =  'LiFiTransferStarted'\n",
    "#             and block_timestamp > current_timestamp - interval '30 days'\n",
    "# ),\n",
    "# {chain}_bridge_data as (\n",
    "#   select '{chain}' as source_chain,\n",
    "#          c.dst_chain,\n",
    "#          r.bridge,\n",
    "#          r.integrator,\n",
    "#          r.tx_hash\n",
    "#   from chain_ids c\n",
    "#         left join \n",
    "#         {chain}_raw_bridge_data r \n",
    "#         using\n",
    "#         (dst_chain_id)\n",
    "\n",
    "# \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f2413-aa28-4afb-ba4e-067db5e890b3",
   "metadata": {},
   "source": [
    "I created the below script to facilitate a rather repetitive process, querying the tables from each chain's schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec4b36-ddea-4ac5-ad8e-27c3c410a060",
   "metadata": {},
   "source": [
    "### Transfer tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd4f22-918e-4b24-ba6c-491a32180d6e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # chains = ['arbitrum', 'bsc', 'optimism', 'base', 'avalanche', 'ethereum','polygon']\n",
    "# sql = \"\"\n",
    "# for chain in chains:\n",
    "#     query = f\"\"\"\n",
    "#     {chain}_transfers as (\n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  'native' as source_token, \n",
    "#     \t  tx_hash \n",
    "#      from {chain}.core.ez_native_transfers\n",
    "#      where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#        and block_timestamp > current_timestamp - interval '30 days'\n",
    "#        and amount_usd >= 20\n",
    "    \n",
    "#     union all\n",
    "    \n",
    "#     select block_timestamp, \n",
    "#     \t  from_address ,\n",
    "#     \t  amount_usd, \n",
    "#     \t  symbol as source_token, \n",
    "#     \t  tx_hash \n",
    "#     from  {chain}.core.ez_token_transfers\n",
    "#     where to_address = '0x1231deb6f5749ef6ce6943a275a1d3e7486f4eae'\n",
    "#       and block_timestamp > current_timestamp - interval '30 days'\n",
    "#       and amount_usd >= 20\n",
    "#     ),\n",
    "#     \"\"\"\n",
    "#     sql = sql + '\\n' + query\n",
    "# print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e590e-e5f6-4014-9846-2977ad6f199b",
   "metadata": {},
   "source": [
    "Almost there! We now union all these tables together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38095ac-0994-4cdd-852a-2de1c6495cbe",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c62a8-8e03-4c7d-a135-fcc29b502c46",
   "metadata": {},
   "source": [
    "Columns needed: \n",
    "  - timestamp\n",
    "  - receiver\n",
    "  - source_chain\n",
    "  - destination_chain   \n",
    "  - amount usd (need to merge with price table\n",
    "  - token_address\n",
    "  - token symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25048bb3-3c67-486a-a939-0dc669329601",
   "metadata": {},
   "outputs": [],
   "source": [
    "id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
